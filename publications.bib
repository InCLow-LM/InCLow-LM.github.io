@misc{https://doi.org/10.48550/arxiv.2504.00597,  doi = {10.48550/ARXIV.2504.00597},  url = {https://arxiv.org/abs/2504.00597},  author = {Qi, Jirui and Fernández, Raquel and Bisazza, Arianna},  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},  title = {On the Consistency of Multilingual Context Utilization in Retrieval-Augmented Generation},  publisher = {arXiv},  year = {2025},  copyright = {Creative Commons Attribution 4.0 International}},
@inproceedings{f719d93eca374965b93569bc53a48a4f,
  title     = "Democratizing Advanced Attribution Analyses of Generative Language Models with the Inseq Toolkit",
  abstract  = "Inseq1 is a recent toolkit providing an intuitive and optimized interface to conduct feature attribution analyses of generative language models. In this work, we present the latest improvements to the library, including efforts to simplify the attribution of large language models on consumer hardware, additional attribution approaches, and a new client command to detect and attribute context usage in language model generations. We showcase an online demo using Inseq as an attribution backbone for context reliance analysis, and we highlight interesting contextual patterns in language model generations. Ultimately, this release furthers Inseq{\textquoteright}s mission of centralizing good interpretability practices and enabling fair and reproducible model evaluations.",
  keywords  = "Feature Attribution, Generative Language Models, Natural Language Processing, Python Toolkit",
  author    = "Gabriele Sarti and Nils Feldhus and Jirui Qi and Malvina Nissim and Arianna Bisazza",
  note      = "Publisher Copyright: {\textcopyright} 2024 Copyright for this paper by its authors.; Joint of the 2nd World Conference on eXplainable Artificial Intelligence Late-Breaking Work, Demos and Doctoral Consortium, xAI-2024:LB/D/DC ; Conference date: 17-07-2024 Through 19-07-2024",
  year      = "2024",
  language  = "English",
  series    = "CEUR Workshop Proceedings",
  publisher = "CEUR Workshop Proceedings (CEUR-WS.org)",
  pages     = "289--296",
  editor    = "Luca Longo and Weiru Liu and Gr{\'e}goire Montavon",
  booktitle = "xAI-2024 Late-breaking Work, Demos and Doctoral Consortium Joint Proceedings",
},
@inproceedings{ed2c4a6c889f4c49b0a0b77197c2b47b,
  title     = "Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation",
  abstract  = "Ensuring the verifiability of model answers is a fundamental challenge for retrieval-augmented generation (RAG) in the question answering (QA) domain. Recently, self-citation prompting was proposed to make large language models (LLMs) generate citations to supporting documents along with their answers. However, self-citing LLMs often struggle to match the required format, refer to non-existent sources, and fail to faithfully reflect LLMs' context usage throughout the generation. In this work, we present MIRAGE --Model Internals-based RAG Explanations -- a plug-and-play approach using model internals for faithful answer attribution in RAG applications. MIRAGE detects context-sensitive answer tokens and pairs them with retrieved documents contributing to their prediction via saliency methods. We evaluate our proposed approach on a multilingual extractive QA dataset, finding high agreement with human answer attribution. On open-ended QA, MIRAGE achieves citation quality and efficiency comparable to self-citation while also allowing for a finer-grained control of attribution parameters. Our qualitative evaluation highlights the faithfulness of MIRAGE's attributions and underscores the promising application of model internals for RAG answer attribution.",
  keywords  = "cs.CL, cs.AI, cs.LG",
  author    = "Jirui Qi and Gabriele Sarti and Raquel Fern{\'a}ndez and Arianna Bisazza",
  year      = "2024",
  doi       = "10.18653/v1/2024.emnlp-main.347",
  language  = "English",
  pages     = "6037--6053",
  editor    = "Yaser Al-Onaizan and Mohit Bansal and Yun-Nung Chen",
  booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
  publisher = "Association for Computational Linguistics (ACL)",
},
 @inproceedings{Chen_2024, title={The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models}, url={http://dx.doi.org/10.18653/v1/2024.findings-emnlp.92}, DOI={10.18653/v1/2024.findings-emnlp.92}, booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024}, publisher={Association for Computational Linguistics}, author={Chen, Xinyi and Liao, Baohao and Qi, Jirui and Eustratiadis, Panagiotis and Monz, Christof and Bisazza, Arianna and de Rijke, Maarten}, year={2024}, pages={1691–1706} }
,
@inproceedings{dafbb4f37d7a454790f0fadb17dda0c5,
  title     = "Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models",
  abstract  = "Multilingual large-scale Pretrained Language Models (PLMs) have been shown to store considerable amounts of factual knowledge, but large variations are observed across languages. With the ultimate goal of ensuring that users with different language backgrounds obtain consistent feedback from the same model, we study the cross-lingual consistency (CLC) of factual knowledge in various multilingual PLMs. To this end, we propose a Ranking-based Consistency (RankC) metric to evaluate knowledge consistency across languages independently from accuracy. Using this metric, we conduct an in-depth analysis of the determining factors for CLC, both at model level and at language-pair level. Among other results, we find that increasing model size leads to higher factual probing accuracy in most languages, but does not improve cross-lingual consistency. Finally, we conduct a case study on CLC when new factual associations are inserted in the PLMs via model editing. Results on a small sample of facts inserted in English reveal a clear pattern whereby the new piece of knowledge transfers only to languages with which English has a high RankC score.",
  author    = "Jirui Qi and Raquel Fern{\'a}ndez and Arianna Bisazza",
  note      = "Publisher Copyright: {\textcopyright}2023 Association for Computational Linguistics.; 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023 ; Conference date: 06-12-2023 Through 10-12-2023",
  year      = "2023",
  doi       = "10.18653/v1/2023.emnlp-main.658",
  language  = "English",
  pages     = "10650--10666",
  editor    = "Houda Bouamor and Juan Pino and Kalika Bali",
  booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
  publisher = "Association for Computational Linguistics, ACL Anthology",
}