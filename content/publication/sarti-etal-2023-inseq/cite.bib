@inproceedings{sarti-etal-2023-inseq,
 abstract = {Past work in natural language processing interpretability focused mainly on popular classification tasks while largely overlooking generation settings, partly due to a lack of dedicated tools. In this work, we introduce Inseq, a Python library to democratize access to interpretability analyses of sequence generation models. Inseq enables intuitive and optimized extraction of models' internal information and feature importance scores for popular decoder-only and encoder-decoder Transformers architectures. We showcase its potential by adopting it to highlight gender biases in machine translation models and locate factual knowledge inside GPT-2. Thanks to its extensible interface supporting cutting-edge techniques such as contrastive feature attribution, Inseq can drive future advances in explainable natural language generation, centralizing good practices and enabling fair and reproducible model evaluations.},
 address = {Toronto, Canada},
 author = {Sarti, Gabriele  and
Feldhus, Nils  and
Sickert, Ludwig  and
van der Wal, Oskar},
 booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
 doi = {10.18653/v1/2023.acl-demo.40},
 editor = {Bollegala, Danushka  and
Huang, Ruihong  and
Ritter, Alan},
 month = {July},
 pages = {421--435},
 publisher = {Association for Computational Linguistics},
 title = {Inseq: An Interpretability Toolkit for Sequence Generation Models},
 url = {https://aclanthology.org/2023.acl-demo.40/},
 year = {2023}
}
